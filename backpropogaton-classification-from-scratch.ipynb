{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-15T03:35:30.162709Z","iopub.execute_input":"2025-01-15T03:35:30.163086Z","iopub.status.idle":"2025-01-15T03:35:31.420395Z","shell.execute_reply.started":"2025-01-15T03:35:30.163055Z","shell.execute_reply":"2025-01-15T03:35:31.419288Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"df = pd.DataFrame([[8,8,1],[7,9,1],[6,10,0],[5,5,0]], columns=['cgpa', 'profile_score', 'placed'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T03:35:36.094499Z","iopub.execute_input":"2025-01-15T03:35:36.094960Z","iopub.status.idle":"2025-01-15T03:35:36.103254Z","shell.execute_reply.started":"2025-01-15T03:35:36.094884Z","shell.execute_reply":"2025-01-15T03:35:36.102221Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T03:35:43.147390Z","iopub.execute_input":"2025-01-15T03:35:43.147713Z","iopub.status.idle":"2025-01-15T03:35:43.173487Z","shell.execute_reply.started":"2025-01-15T03:35:43.147687Z","shell.execute_reply":"2025-01-15T03:35:43.172352Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   cgpa  profile_score  placed\n0     8              8       1\n1     7              9       1\n2     6             10       0\n3     5              5       0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cgpa</th>\n      <th>profile_score</th>\n      <th>placed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8</td>\n      <td>8</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7</td>\n      <td>9</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6</td>\n      <td>10</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5</td>\n      <td>5</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"def initialize_parameters(layer_dims):\n  \n  np.random.seed(3)\n  parameters = {}\n  L = len(layer_dims)         \n\n  for l in range(1, L):\n\n    parameters['W' + str(l)] = np.ones((layer_dims[l-1], layer_dims[l]))*0.1\n    parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n      \n\n  return parameters","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T03:36:29.600298Z","iopub.execute_input":"2025-01-15T03:36:29.600692Z","iopub.status.idle":"2025-01-15T03:36:29.606577Z","shell.execute_reply.started":"2025-01-15T03:36:29.600632Z","shell.execute_reply":"2025-01-15T03:36:29.605433Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Utility Functions\ndef sigmoid(Z):\n  \n  A = 1/(1+np.exp(-Z))\n\n  return A","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T03:36:43.411233Z","iopub.execute_input":"2025-01-15T03:36:43.411597Z","iopub.status.idle":"2025-01-15T03:36:43.416055Z","shell.execute_reply.started":"2025-01-15T03:36:43.411564Z","shell.execute_reply":"2025-01-15T03:36:43.414877Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def linear_forward(A_prev, W, b):\n  \n  Z = np.dot(W.T, A_prev) + b\n\n  A = sigmoid(Z)\n  \n  return A","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T03:36:52.862123Z","iopub.execute_input":"2025-01-15T03:36:52.862471Z","iopub.status.idle":"2025-01-15T03:36:52.867219Z","shell.execute_reply.started":"2025-01-15T03:36:52.862446Z","shell.execute_reply":"2025-01-15T03:36:52.866144Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# L-layer feed forward\n\ndef L_layer_forward(X, parameters):\n\n  A = X\n  L = len(parameters) // 2                  # number of layers in the neural network\n  \n  for l in range(1, L+1):\n    A_prev = A \n    Wl = parameters['W' + str(l)]\n    bl = parameters['b' + str(l)]\n    #print(\"A\"+str(l-1)+\": \", A_prev)\n    #print(\"W\"+str(l)+\": \", Wl)\n    #print(\"b\"+str(l)+\": \", bl)\n    #print(\"--\"*20)\n\n    A = linear_forward(A_prev, Wl, bl)\n    #print(\"A\"+str(l)+\": \", A)\n    #print(\"**\"*20)\n          \n  return A,A_prev\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T03:37:21.502665Z","iopub.execute_input":"2025-01-15T03:37:21.503070Z","iopub.status.idle":"2025-01-15T03:37:21.508745Z","shell.execute_reply.started":"2025-01-15T03:37:21.503041Z","shell.execute_reply":"2025-01-15T03:37:21.507622Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def update_parameters(parameters,y,y_hat,A1,X):\n  parameters['W2'][0][0] = parameters['W2'][0][0] + (0.0001 * (y - y_hat)*A1[0][0])\n  parameters['W2'][1][0] = parameters['W2'][1][0] + (0.0001 * (y - y_hat)*A1[1][0])\n  parameters['b2'][0][0] = parameters['W2'][1][0] + (0.0001 * (y - y_hat))\n\n  parameters['W1'][0][0] = parameters['W1'][0][0] + (0.0001 * (y - y_hat)*parameters['W2'][0][0]*A1[0][0]*(1-A1[0][0])*X[0][0])\n  parameters['W1'][0][1] = parameters['W1'][0][1] + (0.0001 * (y - y_hat)*parameters['W2'][0][0]*A1[0][0]*(1-A1[0][0])*X[1][0])\n  parameters['b1'][0][0] = parameters['b1'][0][0] + (0.0001 * (y - y_hat)*parameters['W2'][0][0]*A1[0][0]*(1-A1[0][0]))\n\n  parameters['W1'][1][0] = parameters['W1'][1][0] + (0.0001 * (y - y_hat)*parameters['W2'][1][0]*A1[1][0]*(1-A1[1][0])*X[0][0])\n  parameters['W1'][1][1] = parameters['W1'][1][1] + (0.0001 * (y - y_hat)*parameters['W2'][1][0]*A1[1][0]*(1-A1[1][0])*X[1][0])\n  parameters['b1'][1][0] = parameters['b1'][1][0] + (0.0001 * (y - y_hat)*parameters['W2'][1][0]*A1[1][0]*(1-A1[1][0]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T03:37:37.578085Z","iopub.execute_input":"2025-01-15T03:37:37.578424Z","iopub.status.idle":"2025-01-15T03:37:37.589531Z","shell.execute_reply.started":"2025-01-15T03:37:37.578399Z","shell.execute_reply":"2025-01-15T03:37:37.588036Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"X = df[['cgpa', 'profile_score']].values[0].reshape(2,1) # Shape(no of features, no. of training example)\ny = df[['placed']].values[0][0]\n\n# Parameter initialization\nparameters = initialize_parameters([2,2,1])\n\ny_hat,A1 = L_layer_forward(X,parameters)\ny_hat = y_hat[0][0]\n\nupdate_parameters(parameters,y,y_hat,A1,X)\n\nprint('Loss for this student - ',-y*np.log(y_hat) - (1-y)*np.log(1-y_hat))\n\nparameters","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T03:38:05.137264Z","iopub.execute_input":"2025-01-15T03:38:05.137696Z","iopub.status.idle":"2025-01-15T03:38:05.161171Z","shell.execute_reply.started":"2025-01-15T03:38:05.137659Z","shell.execute_reply":"2025-01-15T03:38:05.159870Z"}},"outputs":[{"name":"stdout","text":"Loss for this student -  0.613402628898913\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"{'W1': array([[0.10000513, 0.10000513],\n        [0.10000513, 0.10000513]]),\n 'b1': array([[6.41054186e-07],\n        [6.41054186e-07]]),\n 'W2': array([[0.10003815],\n        [0.10003815]]),\n 'b2': array([[0.100084]])}"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"X = df[['cgpa', 'profile_score']].values[1].reshape(2,1) # Shape(no of features, no. of training example)\ny = df[['placed']].values[1][0]\n\ny_hat,A1 = L_layer_forward(X,parameters)\ny_hat = y_hat[0][0]\n\nupdate_parameters(parameters,y,y_hat,A1,X)\n\nprint('Loss for this student - ',-y*np.log(y_hat) - (1-y)*np.log(1-y_hat))\n\nparameters","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T03:38:25.210626Z","iopub.execute_input":"2025-01-15T03:38:25.211004Z","iopub.status.idle":"2025-01-15T03:38:25.224257Z","shell.execute_reply.started":"2025-01-15T03:38:25.210973Z","shell.execute_reply":"2025-01-15T03:38:25.223021Z"}},"outputs":[{"name":"stdout","text":"Loss for this student -  0.568725622654268\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"{'W1': array([[0.10000937, 0.10001059],\n        [0.10000937, 0.10001059]]),\n 'b1': array([[1.24770113e-06],\n        [1.24770113e-06]]),\n 'W2': array([[0.10007424],\n        [0.10007424]]),\n 'b2': array([[0.10011761]])}"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"X = df[['cgpa', 'profile_score']].values[2].reshape(2,1) # Shape(no of features, no. of training example)\ny = df[['placed']].values[2][0]\n\ny_hat,A1 = L_layer_forward(X,parameters)\ny_hat = y_hat[0][0]\n\nupdate_parameters(parameters,y,y_hat,A1,X)\n\nprint('Loss for this student - ',-y*np.log(y_hat) - (1-y)*np.log(1-y_hat))\n\nparameters","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T03:38:34.815318Z","iopub.execute_input":"2025-01-15T03:38:34.815663Z","iopub.status.idle":"2025-01-15T03:38:34.829110Z","shell.execute_reply.started":"2025-01-15T03:38:34.815633Z","shell.execute_reply":"2025-01-15T03:38:34.827934Z"}},"outputs":[{"name":"stdout","text":"Loss for this student -  0.8353333695154365\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"{'W1': array([[0.10000463, 0.10000267],\n        [0.10000463, 0.10000267]]),\n 'b1': array([[4.56125378e-07],\n        [4.56135584e-07]]),\n 'W2': array([[0.10002712],\n        [0.10002712]]),\n 'b2': array([[0.09997049]])}"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"X = df[['cgpa', 'profile_score']].values[3].reshape(2,1) # Shape(no of features, no. of training example)\ny = df[['placed']].values[3][0]\n\ny_hat,A1 = L_layer_forward(X,parameters)\ny_hat = y_hat[0][0]\n\nupdate_parameters(parameters,y,y_hat,A1,X)\n\nprint('Loss for this student - ',-y*np.log(y_hat) - (1-y)*np.log(1-y_hat))\n\nparameters","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T03:38:44.002490Z","iopub.execute_input":"2025-01-15T03:38:44.002833Z","iopub.status.idle":"2025-01-15T03:38:44.015489Z","shell.execute_reply.started":"2025-01-15T03:38:44.002790Z","shell.execute_reply":"2025-01-15T03:38:44.014030Z"}},"outputs":[{"name":"stdout","text":"Loss for this student -  0.8238180133031612\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"{'W1': array([[0.09999911, 0.09999716],\n        [0.09999911, 0.09999716]]),\n 'b1': array([[-6.47175329e-07],\n        [-6.47175081e-07]]),\n 'W2': array([[0.09998609],\n        [0.09998609]]),\n 'b2': array([[0.09992997]])}"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"# epochs implementation\n\nparameters = initialize_parameters([2,2,1])\nepochs = 50\n\nfor i in range(epochs):\n\n  Loss = []\n\n  for j in range(df.shape[0]):\n\n    X = df[['cgpa', 'profile_score']].values[j].reshape(2,1) # Shape(no of features, no. of training example)\n    y = df[['placed']].values[j][0]\n\n    # Parameter initialization\n\n\n    y_hat,A1 = L_layer_forward(X,parameters)\n    y_hat = y_hat[0][0]\n\n    update_parameters(parameters,y,y_hat,A1,X)\n\n    Loss.append(-y*np.log(y_hat) - (1-y)*np.log(1-y_hat))\n\n  print('Epoch - ',i+1,'Loss - ',np.array(Loss).mean())\n\nparameters","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T03:38:52.985428Z","iopub.execute_input":"2025-01-15T03:38:52.985762Z","iopub.status.idle":"2025-01-15T03:38:53.252500Z","shell.execute_reply.started":"2025-01-15T03:38:52.985736Z","shell.execute_reply":"2025-01-15T03:38:53.251324Z"}},"outputs":[{"name":"stdout","text":"Epoch -  1 Loss -  0.7103199085929446\nEpoch -  2 Loss -  0.6991702892802629\nEpoch -  3 Loss -  0.6991679314811485\nEpoch -  4 Loss -  0.6991655746710999\nEpoch -  5 Loss -  0.6991632188496667\nEpoch -  6 Loss -  0.699160864016399\nEpoch -  7 Loss -  0.6991585101708473\nEpoch -  8 Loss -  0.6991561573125619\nEpoch -  9 Loss -  0.6991538054410936\nEpoch -  10 Loss -  0.6991514545559935\nEpoch -  11 Loss -  0.6991491046568126\nEpoch -  12 Loss -  0.6991467557431024\nEpoch -  13 Loss -  0.6991444078144144\nEpoch -  14 Loss -  0.6991420608703007\nEpoch -  15 Loss -  0.6991397149103132\nEpoch -  16 Loss -  0.6991373699340042\nEpoch -  17 Loss -  0.6991350259409265\nEpoch -  18 Loss -  0.6991326829306324\nEpoch -  19 Loss -  0.6991303409026751\nEpoch -  20 Loss -  0.699127999856608\nEpoch -  21 Loss -  0.6991256597919842\nEpoch -  22 Loss -  0.6991233207083575\nEpoch -  23 Loss -  0.6991209826052818\nEpoch -  24 Loss -  0.699118645482311\nEpoch -  25 Loss -  0.6991163093389996\nEpoch -  26 Loss -  0.699113974174902\nEpoch -  27 Loss -  0.6991116399895729\nEpoch -  28 Loss -  0.6991093067825676\nEpoch -  29 Loss -  0.699106974553441\nEpoch -  30 Loss -  0.6991046433017485\nEpoch -  31 Loss -  0.6991023130270458\nEpoch -  32 Loss -  0.699099983728889\nEpoch -  33 Loss -  0.6990976554068338\nEpoch -  34 Loss -  0.6990953280604367\nEpoch -  35 Loss -  0.6990930016892543\nEpoch -  36 Loss -  0.6990906762928432\nEpoch -  37 Loss -  0.6990883518707602\nEpoch -  38 Loss -  0.6990860284225631\nEpoch -  39 Loss -  0.6990837059478086\nEpoch -  40 Loss -  0.6990813844460546\nEpoch -  41 Loss -  0.699079063916859\nEpoch -  42 Loss -  0.6990767443597797\nEpoch -  43 Loss -  0.6990744257743753\nEpoch -  44 Loss -  0.699072108160204\nEpoch -  45 Loss -  0.6990697915168249\nEpoch -  46 Loss -  0.6990674758437966\nEpoch -  47 Loss -  0.6990651611406782\nEpoch -  48 Loss -  0.6990628474070294\nEpoch -  49 Loss -  0.6990605346424095\nEpoch -  50 Loss -  0.6990582228463785\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"{'W1': array([[0.09994267, 0.09984548],\n        [0.09994272, 0.09984548]]),\n 'b1': array([[-3.38405750e-05],\n        [-3.38419977e-05]]),\n 'W2': array([[0.09920806],\n        [0.09920816]]),\n 'b2': array([[0.09915209]])}"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}