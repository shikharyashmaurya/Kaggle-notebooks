{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Efficient Multi-GPU Training with PyTorch FSDP\n\n## Introduction\n\nThis example demonstrates how to implement both distributed and single GPU training using PyTorch. The code is organized into several blocks that cover importing libraries, defining a simple convolutional neural network (CNN) model for MNIST digit classification, and setting up distributed training using Fully Sharded Data Parallel (FSDP). Additionally, it provides fallback mechanisms to run on a single GPU if multiple GPUs are not available. Each section includes detailed comments explaining its purpose and functionality, making the example useful for understanding distributed training strategies and optimizing deep learning workflows in PyTorch.","metadata":{}},{"cell_type":"markdown","source":"## 1. Import Statements and Environment Setup  \n\nThis block imports necessary libraries for PyTorch, distributed training, data loading, and data transformations. It also sets up the environment for CUDA operations.","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, DistributedSampler\nfrom torchvision import datasets, transforms\nimport torch.distributed as dist","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T07:26:27.837749Z","iopub.execute_input":"2025-04-14T07:26:27.838142Z","iopub.status.idle":"2025-04-14T07:26:27.842409Z","shell.execute_reply.started":"2025-04-14T07:26:27.838112Z","shell.execute_reply":"2025-04-14T07:26:27.841599Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"## 2. GPU Availability Check  \n\nThis function checks the number of available GPUs on the machine. It uses PyTorch’s CUDA utilities to determine if there are sufficient GPUs for distributed training.","metadata":{}},{"cell_type":"code","source":"def check_gpu_availability():\n    # Get the number of available GPUs\n    num_gpus = torch.cuda.device_count()\n    print(f\"Number of GPUs available: {num_gpus}\")\n    return num_gpus","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T07:26:29.684442Z","iopub.execute_input":"2025-04-14T07:26:29.684711Z","iopub.status.idle":"2025-04-14T07:26:29.688525Z","shell.execute_reply.started":"2025-04-14T07:26:29.684688Z","shell.execute_reply":"2025-04-14T07:26:29.687574Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"## 3. SimpleCNN Model Definition  \n\nThis block defines a simple convolutional neural network (CNN) using PyTorch's nn.Module. The network consists of two convolutional layers, followed by ReLU activations, max pooling layers, and a fully connected output layer designed for MNIST images.","metadata":{}},{"cell_type":"code","source":"class SimpleCNN(nn.Module):\n    def __init__(self):\n        super(SimpleCNN, self).__init__()\n        # First convolutional layer: input channels=1, output channels=32\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n        self.relu1 = nn.ReLU()  # Activation function after conv1\n        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)  # Reduces spatial dimensions\n        \n        # Second convolutional layer: input channels=32, output channels=64\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.relu2 = nn.ReLU()  # Activation function after conv2\n        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)  # Further reduces spatial dimensions\n        \n        # Fully connected layer that maps the flattened output to 10 classes (MNIST)\n        self.fc = nn.Linear(64 * 7 * 7, 10)  # Assuming input image size is 28x28\n\n    def forward(self, x):\n        x = self.pool1(self.relu1(self.conv1(x)))   # Apply first convolution, activation and pooling\n        x = self.pool2(self.relu2(self.conv2(x)))   # Apply second convolution, activation and pooling\n        x = x.view(-1, 64 * 7 * 7)                  # Flatten the output for the fully connected layer\n        x = self.fc(x)                              # Final classification layer\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T07:26:31.821382Z","iopub.execute_input":"2025-04-14T07:26:31.821692Z","iopub.status.idle":"2025-04-14T07:26:31.827591Z","shell.execute_reply.started":"2025-04-14T07:26:31.821669Z","shell.execute_reply":"2025-04-14T07:26:31.826759Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"## 4. Distributed Training Setup and Cleanup  \n\nThis block defines helper functions for distributed training. The `setup` function initializes the process group for distributed training using the NCCL backend, while `cleanup` destroys the process group once training is complete.","metadata":{}},{"cell_type":"code","source":"def setup(rank, world_size):\n    \"\"\"Sets up the process group for distributed training.\"\"\"\n    # Set environment variables for master address and port\n    os.environ['MASTER_ADDR'] = 'localhost'\n    os.environ['MASTER_PORT'] = '12355'\n    \n    # Initialize the distributed process group using NCCL backend (optimized for GPUs)\n    dist.init_process_group(\"nccl\", rank=rank, world_size=world_size)\n    # Set the current device based on the rank\n    torch.cuda.set_device(rank)\n\ndef cleanup():\n    \"\"\"Cleans up the distributed process group.\"\"\"\n    if dist.is_initialized():\n        dist.destroy_process_group()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T07:20:10.534460Z","iopub.execute_input":"2025-04-14T07:20:10.534740Z","iopub.status.idle":"2025-04-14T07:20:10.539061Z","shell.execute_reply.started":"2025-04-14T07:20:10.534719Z","shell.execute_reply":"2025-04-14T07:20:10.538170Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## 5. Distributed Training Function Using FSDP  \n\nThis function handles distributed training using Fully Sharded Data Parallel (FSDP). It sets up the training environment, loads the MNIST dataset with a distributed sampler, wraps the model with FSDP, and executes the training loop with logging for every 100 batches on the primary GPU.","metadata":{}},{"cell_type":"code","source":"def train_distributed(rank, world_size, epochs=2):\n    \"\"\"Trains the model using FSDP with multiple GPUs.\"\"\"\n    try:\n        # Set up distributed environment for current rank\n        setup(rank, world_size)\n        device = torch.device(f\"cuda:{rank}\")\n        \n        # Import FSDP-related modules here to prevent issues on single-GPU setups\n        from torch.distributed.fsdp import FullyShardedDataParallel as FSDP\n        \n        # Attempt to import size_based_auto_wrap_policy based on the PyTorch version\n        try:\n            from torch.distributed.fsdp.wrap import size_based_auto_wrap_policy\n        except ImportError:\n            try:\n                from torch.distributed.fsdp import size_based_auto_wrap_policy\n            except ImportError:\n                # Define a simple custom policy if the import fails\n                def size_based_auto_wrap_policy(module, recurse, unwrapped_params, min_num_params=1e8):\n                    return sum(p.numel() for p in unwrapped_params) > min_num_params\n\n        # Define data transformations for the MNIST dataset\n        transform = transforms.Compose([\n            transforms.ToTensor(),\n            transforms.Normalize((0.1307,), (0.3081,))\n        ])\n        \n        # Load MNIST training dataset\n        dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n        # Create a DistributedSampler for the dataset\n        sampler = DistributedSampler(dataset, num_replicas=world_size, rank=rank)\n        # Define DataLoader with distributed sampler\n        dataloader = DataLoader(dataset, batch_size=64, sampler=sampler, num_workers=2)\n\n        # Instantiate the SimpleCNN model and move it to the designated GPU\n        model = SimpleCNN().to(device)\n        # Define the loss function (cross entropy) and move it to the GPU\n        criterion = nn.CrossEntropyLoss().to(device)\n        # Define the optimizer (Adam)\n        optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n        # Wrap the model with FSDP for distributed training\n        fsdp_model = FSDP(model, auto_wrap_policy=size_based_auto_wrap_policy)\n\n        # Training loop\n        for epoch in range(epochs):\n            fsdp_model.train()\n            # Ensure that the sampler shuffles differently every epoch\n            sampler.set_epoch(epoch)\n            for batch_idx, (data, target) in enumerate(dataloader):\n                # Move data and labels to the designated GPU\n                data, target = data.to(device), target.to(device)\n                optimizer.zero_grad()             # Reset gradients\n                output = fsdp_model(data)         # Forward pass\n                loss = criterion(output, target)  # Compute loss\n                loss.backward()                   # Backward pass\n                optimizer.step()                  # Update weights\n\n                # Print training status for the primary GPU only\n                if batch_idx % 100 == 0 and rank == 0:\n                    print(f\"Rank {rank}, Epoch: {epoch}, Batch: {batch_idx}/{len(dataloader)}, Loss: {loss.item():.4f}\")\n\n        if rank == 0:\n            print(\"Distributed training finished!\")\n    except Exception as e:\n        print(f\"Error in rank {rank}: {str(e)}\")\n    finally:\n        # Clean up the distributed process group\n        cleanup()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T07:18:28.023564Z","iopub.execute_input":"2025-04-14T07:18:28.023855Z","iopub.status.idle":"2025-04-14T07:18:28.031807Z","shell.execute_reply.started":"2025-04-14T07:18:28.023815Z","shell.execute_reply":"2025-04-14T07:18:28.031045Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## 6. Single GPU Training Function  \n\nThis function performs training on a single GPU without using FSDP. It loads the MNIST dataset, defines the model, loss function, optimizer, and executes the training loop with status logging.","metadata":{}},{"cell_type":"code","source":"def train_single_gpu(epochs=2):\n    \"\"\"Trains the model on a single GPU without FSDP.\"\"\"\n    # Select the appropriate device (GPU if available, otherwise CPU)\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    print(f\"Using device: {device}\")\n    \n    # Define data transformations for MNIST\n    transform = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize((0.1307,), (0.3081,))\n    ])\n    \n    # Load MNIST dataset\n    dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n    # DataLoader for batching and shuffling\n    dataloader = DataLoader(dataset, batch_size=64, shuffle=True, num_workers=2)\n\n    # Instantiate the SimpleCNN model and move it to the device\n    model = SimpleCNN().to(device)\n    # Define the loss function and optimizer\n    criterion = nn.CrossEntropyLoss().to(device)\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    # Training loop\n    for epoch in range(epochs):\n        model.train()\n        for batch_idx, (data, target) in enumerate(dataloader):\n            # Move data and target to the device\n            data, target = data.to(device), target.to(device)\n            optimizer.zero_grad()             # Reset gradients\n            output = model(data)              # Forward pass\n            loss = criterion(output, target)  # Compute loss\n            loss.backward()                   # Backward pass\n            optimizer.step()                  # Update model parameters\n\n            # Print training progress every 100 batches\n            if batch_idx % 100 == 0:\n                print(f\"Epoch: {epoch}, Batch: {batch_idx}/{len(dataloader)}, Loss: {loss.item():.4f}\")\n    \n    print(\"Single GPU training finished!\")\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T07:18:31.608083Z","iopub.execute_input":"2025-04-14T07:18:31.608359Z","iopub.status.idle":"2025-04-14T07:18:31.615084Z","shell.execute_reply.started":"2025-04-14T07:18:31.608338Z","shell.execute_reply":"2025-04-14T07:18:31.614155Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## 7. Main Training Launcher  \n\nThis section determines whether to run distributed training or single GPU training based on the number of available GPUs. It spawns multiple processes for distributed training if two or more GPUs are detected, otherwise it falls back to single GPU training.","metadata":{}},{"cell_type":"code","source":"def run_training():\n    \"\"\"Spawns processes for multi-GPU training or runs single GPU training based on availability.\"\"\"\n    num_gpus = check_gpu_availability()\n    \n    if num_gpus >= 2:\n        print(f\"Running with distributed training on {num_gpus} GPUs\")\n        world_size = num_gpus\n        try:\n            # Spawn processes for distributed training using the available GPUs\n            torch.multiprocessing.spawn(train_distributed,\n                                        args=(world_size,),\n                                        nprocs=world_size,\n                                        join=True)\n        except Exception as e:\n            print(f\"Distributed training failed with error: {str(e)}\")\n            print(\"Falling back to single GPU training\")\n            train_single_gpu()\n    else:\n        print(\"Not enough GPUs for distributed training, using single GPU mode\")\n        train_single_gpu()\n\n# Execute training when the script is run directly\nif __name__ == \"__main__\":\n    run_training()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T07:18:34.325473Z","iopub.execute_input":"2025-04-14T07:18:34.325777Z","iopub.status.idle":"2025-04-14T07:18:59.037545Z","shell.execute_reply.started":"2025-04-14T07:18:34.325753Z","shell.execute_reply":"2025-04-14T07:18:59.036653Z"}},"outputs":[{"name":"stdout","text":"Number of GPUs available: 2\nRunning with distributed training on 2 GPUs\n","output_type":"stream"},{"name":"stderr","text":"W0414 07:18:36.912000 31 torch/multiprocessing/spawn.py:160] Terminating process 65 via signal SIGTERM\n","output_type":"stream"},{"name":"stdout","text":"Distributed training failed with error: process 1 terminated with exit code 1\nFalling back to single GPU training\nUsing device: cuda:0\nDownloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\nFailed to download (trying next):\nHTTP Error 404: Not Found\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 9.91M/9.91M [00:00<00:00, 60.2MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\nFailed to download (trying next):\nHTTP Error 404: Not Found\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 28.9k/28.9k [00:00<00:00, 1.65MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\nFailed to download (trying next):\nHTTP Error 404: Not Found\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1.65M/1.65M [00:00<00:00, 14.2MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\nFailed to download (trying next):\nHTTP Error 404: Not Found\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4.54k/4.54k [00:00<00:00, 7.04MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n\nEpoch: 0, Batch: 0/938, Loss: 2.3069\nEpoch: 0, Batch: 100/938, Loss: 0.1601\nEpoch: 0, Batch: 200/938, Loss: 0.1409\nEpoch: 0, Batch: 300/938, Loss: 0.0263\nEpoch: 0, Batch: 400/938, Loss: 0.0408\nEpoch: 0, Batch: 500/938, Loss: 0.0309\nEpoch: 0, Batch: 600/938, Loss: 0.0319\nEpoch: 0, Batch: 700/938, Loss: 0.0488\nEpoch: 0, Batch: 800/938, Loss: 0.1460\nEpoch: 0, Batch: 900/938, Loss: 0.0267\nEpoch: 1, Batch: 0/938, Loss: 0.0619\nEpoch: 1, Batch: 100/938, Loss: 0.0113\nEpoch: 1, Batch: 200/938, Loss: 0.0156\nEpoch: 1, Batch: 300/938, Loss: 0.0272\nEpoch: 1, Batch: 400/938, Loss: 0.1430\nEpoch: 1, Batch: 500/938, Loss: 0.0045\nEpoch: 1, Batch: 600/938, Loss: 0.1344\nEpoch: 1, Batch: 700/938, Loss: 0.0099\nEpoch: 1, Batch: 800/938, Loss: 0.0446\nEpoch: 1, Batch: 900/938, Loss: 0.0045\nSingle GPU training finished!\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"## Conclusion\n\nThe provided example effectively illustrates the practical aspects of both distributed and single GPU training in PyTorch. By modularizing the code into clear sections, it becomes easier to understand how to:\n- Check for GPU availability and decide on the training mode,\n- Set up a distributed environment using PyTorch's NCCL backend,\n- Implement and wrap a neural network model with FSDP for scalable training,\n- Handle data loading with distributed samplers for the MNIST dataset,\n- Fallback gracefully to a single GPU training regime when necessary.\n\nOverall, the code serves as a comprehensive guide for developers aiming to leverage the benefits of distributed computing for deep learning applications, while also ensuring compatibility with setups that only have access to a single GPU.","metadata":{}}]}