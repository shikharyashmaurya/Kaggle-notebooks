{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Qwen2.5-Coder-1.5B","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM\nimport torch\n\n# Load tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-Coder-1.5B-Instruct\", trust_remote_code=True)\n\n# Load model with memory optimization using bfloat16 precision\nmodel = AutoModelForCausalLM.from_pretrained(\n    \"Qwen/Qwen2.5-Coder-1.5B-Instruct\", \n    trust_remote_code=True, \n    torch_dtype=torch.bfloat16\n).cuda()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T17:59:46.346824Z","iopub.execute_input":"2025-03-07T17:59:46.347122Z","iopub.status.idle":"2025-03-07T18:00:41.404608Z","shell.execute_reply.started":"2025-03-07T17:59:46.347092Z","shell.execute_reply":"2025-03-07T18:00:41.403687Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/7.30k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71a934a397dc440eb6fecfc794dbe24e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"890d4906e6054d618b8a3f7f2fc7af4a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"977532055240498399f0d60bdef47d34"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cbbc8eee9c1540c9aae237ed8463e556"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/660 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9f81fd462db41a499778f6094c86965"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/3.09G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65f7243ced66401e9b95a98b64310b87"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9fbaf13653654d0f84ab8f5c899ffb8b"}},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\n# Assume tokenizer and model are already loaded\n# tokenizer = AutoTokenizer.from_pretrained(\"some-chat-model\")\n# model = AutoModelForCausalLM.from_pretrained(\"some-chat-model\")\n\nmessages = [{'role': 'user', 'content': \"Write a Python function of bubble sort\"}]\n\n# Apply chat template and move to device\ninputs = tokenizer.apply_chat_template(messages, return_tensors=\"pt\").to(model.device)\n\n# Handle different possible return types\nif isinstance(inputs, torch.Tensor):\n    # If inputs is a tensor, assume it's input_ids\n    current_input = inputs\n    # Create attention_mask (all ones) if not provided\n    attention_mask = torch.ones_like(current_input, device=current_input.device)\nelif isinstance(inputs, dict):\n    # If inputs is a dictionary, access input_ids and attention_mask\n    current_input = inputs['input_ids']\n    attention_mask = inputs.get('attention_mask', torch.ones_like(current_input, device=current_input.device))\nelse:\n    raise ValueError(f\"Unexpected return type from apply_chat_template: {type(inputs)}\")\n\n# Ensure tensors are 2D (batch_size, sequence_length)\nif current_input.dim() == 1:\n    current_input = current_input.unsqueeze(0)\n    attention_mask = attention_mask.unsqueeze(0)\nelif current_input.dim() != 2:\n    raise ValueError(f\"input_ids must be 1D or 2D, got {current_input.dim()}D\")\n\n# Proceed with generation\ngenerated_tokens = []\n\nprint(\"Generating tokens:\")\nwhile len(generated_tokens) < 2048:\n    outputs = model.generate(\n        input_ids=current_input,\n        attention_mask=attention_mask,\n        max_new_tokens=1,\n        do_sample=True,\n        temperature=0.7,\n        top_p=0.95,\n        eos_token_id=tokenizer.eos_token_id,\n        pad_token_id=tokenizer.eos_token_id\n    )\n    next_token = outputs[0, -1]  # Last token in the sequence (batch_size=1)\n    generated_tokens.append(next_token)\n\n    if next_token == tokenizer.eos_token_id:\n        break\n\n    # Append the new token to the input sequence\n    next_token_tensor = next_token.unsqueeze(0).unsqueeze(0)  # Shape (1, 1)\n    current_input = torch.cat([current_input, next_token_tensor], dim=1)\n    attention_mask = torch.cat([attention_mask, torch.ones((1, 1), dtype=attention_mask.dtype, device=attention_mask.device)], dim=1)\n\n    # Print the decoded token\n    print(tokenizer.decode(next_token, skip_special_tokens=True), end=' ')\n\n# Decode and print the final generated code\ngenerated_code = tokenizer.decode(generated_tokens, skip_special_tokens=True)\nprint(\"\\n\\nFinal generated code:\\n\")\nprint(generated_code)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T18:00:41.405576Z","iopub.execute_input":"2025-03-07T18:00:41.406249Z","iopub.status.idle":"2025-03-07T18:01:31.637439Z","shell.execute_reply.started":"2025-03-07T18:00:41.406214Z","shell.execute_reply":"2025-03-07T18:01:31.636739Z"}},"outputs":[{"name":"stdout","text":"Generating tokens:\n   \n  \n ``` python \n def  bubble _sort (arr ):\n      n  =  len (arr )\n     \n      #  Traverse  through  all  array  elements \n      for  i  in  range (n ):\n          #  Last  i  elements  are  already  in  place \n          for  j  in  range ( 0 ,  n -i - 1 ):\n              #  Traverse  the  array  from   0  to  n -i - 1 \n              #  Swap  if  the  element  found  is  greater  than  the  next  element \n              if  arr [j ]  >  arr [j + 1 ]:\n                  arr [j ],  arr [j + 1 ]  =  arr [j + 1 ],  arr [j ]\n                 \n      return  arr \n\n #  Example  usage :\n arr  =  [ 6 4 ,   3 4 ,   2 5 ,   1 2 ,   2 2 ,   1 1 ,   9 0 ]\n print (\" Sorted  array :\",  bubble _sort (arr ))\n `` `\n\n This  Python  function  implements  the  bubble  sort  algorithm ,  which  repeatedly  steps  through  the  list ,  compares  adjacent  elements  and  swaps  them  if  they  are  in  the  wrong  order .  The  pass  through  the  list  is  repeated  until  the  list  is  sorted .  This  algorithm  has  a  time  complexity  of  O (n ^ 2 ),  making  it  inefficient  for  large  lists .  However ,  it  is  simple  and  easy  to  understand . \n\nFinal generated code:\n\n\n\n```python\ndef bubble_sort(arr):\n    n = len(arr)\n    \n    # Traverse through all array elements\n    for i in range(n):\n        # Last i elements are already in place\n        for j in range(0, n-i-1):\n            # Traverse the array from 0 to n-i-1\n            # Swap if the element found is greater than the next element\n            if arr[j] > arr[j+1]:\n                arr[j], arr[j+1] = arr[j+1], arr[j]\n                \n    return arr\n\n# Example usage:\narr = [64, 34, 25, 12, 22, 11, 90]\nprint(\"Sorted array:\", bubble_sort(arr))\n```\n\nThis Python function implements the bubble sort algorithm, which repeatedly steps through the list, compares adjacent elements and swaps them if they are in the wrong order. The pass through the list is repeated until the list is sorted. This algorithm has a time complexity of O(n^2), making it inefficient for large lists. However, it is simple and easy to understand.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}