{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport librosa\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torchvision\nfrom skimage.transform import resize","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T21:58:02.558464Z","iopub.execute_input":"2025-03-11T21:58:02.558789Z","iopub.status.idle":"2025-03-11T21:58:10.198364Z","shell.execute_reply.started":"2025-03-11T21:58:02.558764Z","shell.execute_reply":"2025-03-11T21:58:10.197329Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Set seed for reproducibility\nnp.random.seed(42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T21:58:14.393534Z","iopub.execute_input":"2025-03-11T21:58:14.394072Z","iopub.status.idle":"2025-03-11T21:58:14.398238Z","shell.execute_reply.started":"2025-03-11T21:58:14.394041Z","shell.execute_reply":"2025-03-11T21:58:14.397057Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Define class labels from training audio directories\nclass_labels = sorted(os.listdir('/kaggle/input/birdclef-2025/train_audio/'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T21:58:15.543691Z","iopub.execute_input":"2025-03-11T21:58:15.544086Z","iopub.status.idle":"2025-03-11T21:58:15.556086Z","shell.execute_reply.started":"2025-03-11T21:58:15.544055Z","shell.execute_reply":"2025-03-11T21:58:15.555033Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Define the model architecture\nclass BirdCLEFModel(torch.nn.Module):\n    def __init__(self, num_classes):\n        super(BirdCLEFModel, self).__init__()\n        # Load ResNet18 without pre-trained weights (will load custom weights)\n        self.resnet = torchvision.models.resnet18(pretrained=False)\n        # Modify first conv layer for 1-channel input (spectrograms)\n        self.resnet.conv1 = torch.nn.Conv2d(\n            in_channels=1,\n            out_channels=64,\n            kernel_size=(7, 7),\n            stride=(2, 2),\n            padding=(3, 3),\n            bias=False\n        )\n        # Modify final fully connected layer for num_classes outputs\n        self.resnet.fc = torch.nn.Linear(self.resnet.fc.in_features, num_classes)\n        self.sigmoid = torch.nn.Sigmoid()  # For probability outputs\n\n    def forward(self, x):\n        x = self.resnet(x)\n        x = self.sigmoid(x)  # Output probabilities between 0 and 1\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T21:58:17.718852Z","iopub.execute_input":"2025-03-11T21:58:17.719229Z","iopub.status.idle":"2025-03-11T21:58:17.725427Z","shell.execute_reply.started":"2025-03-11T21:58:17.719201Z","shell.execute_reply":"2025-03-11T21:58:17.724266Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Instantiate the model\nmodel = BirdCLEFModel(num_classes=len(class_labels))\n\n# Load pre-trained weights from uploaded dataset\n# Note: Replace '/kaggle/input/birdclef-model-weights/model_weights.pth' with your dataset path\nmodel.load_state_dict(\n    torch.load(\n        # '/kaggle/input/birdclef-model-weights/model_weights.pth',\n        '/kaggle/input/model_weight/pytorch/default/1/model_weights.pth',\n        map_location=torch.device('cpu')\n    )\n)\nmodel.eval()  # Set to evaluation mode","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T22:03:18.718463Z","iopub.execute_input":"2025-03-11T22:03:18.718856Z","iopub.status.idle":"2025-03-11T22:03:19.500773Z","shell.execute_reply.started":"2025-03-11T22:03:18.718824Z","shell.execute_reply":"2025-03-11T22:03:19.499847Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-6-db12445d7ecc>:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  torch.load(\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"BirdCLEFModel(\n  (resnet): ResNet(\n    (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): ReLU(inplace=True)\n    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (layer1): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (layer2): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (layer3): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (layer4): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n    (fc): Linear(in_features=512, out_features=206, bias=True)\n  )\n  (sigmoid): Sigmoid()\n)"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"# Function to convert audio to mel-spectrogram\ndef audio_to_spectrogram(audio, sr, n_mels=128, fmin=0, fmax=None, n_fft=1024, hop_length=512):\n    \"\"\"Convert audio to mel-spectrogram.\"\"\"\n    S = librosa.feature.melspectrogram(\n        y=audio,\n        sr=sr,\n        n_mels=n_mels,\n        fmin=fmin,\n        fmax=fmax,\n        n_fft=n_fft,\n        hop_length=hop_length\n    )\n    S_dB = librosa.power_to_db(S, ref=np.max)  # Convert to dB scale\n    return S_dB","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T22:03:31.479005Z","iopub.execute_input":"2025-03-11T22:03:31.479356Z","iopub.status.idle":"2025-03-11T22:03:31.484558Z","shell.execute_reply.started":"2025-03-11T22:03:31.479329Z","shell.execute_reply":"2025-03-11T22:03:31.483438Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# List test soundscapes\ntest_soundscape_path = '/kaggle/input/birdclef-2025/test_soundscapes/'\ntest_soundscapes = [\n    os.path.join(test_soundscape_path, afile)\n    for afile in sorted(os.listdir(test_soundscape_path))\n    if afile.endswith('.ogg')\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T22:03:41.958695Z","iopub.execute_input":"2025-03-11T22:03:41.959076Z","iopub.status.idle":"2025-03-11T22:03:41.967996Z","shell.execute_reply.started":"2025-03-11T22:03:41.959040Z","shell.execute_reply":"2025-03-11T22:03:41.967084Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Initialize predictions DataFrame\npredictions = pd.DataFrame(columns=['row_id'] + class_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T22:03:59.838707Z","iopub.execute_input":"2025-03-11T22:03:59.839085Z","iopub.status.idle":"2025-03-11T22:03:59.855977Z","shell.execute_reply.started":"2025-03-11T22:03:59.839055Z","shell.execute_reply":"2025-03-11T22:03:59.854855Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Process each soundscape\nfor soundscape in test_soundscapes:\n    # Load audio\n    sig, rate = librosa.load(soundscape, sr=None)\n    chunk_length = 5 * rate  # 5 seconds in samples\n    num_chunks = len(sig) // chunk_length  # Number of full 5-second chunks\n    spectrograms = []\n\n    # Split into 5-second chunks and compute spectrograms\n    for i in range(num_chunks):\n        chunk = sig[i * chunk_length:(i + 1) * chunk_length]\n        S = audio_to_spectrogram(chunk, rate)\n        # Resize spectrogram to fixed size (e.g., 128x256) for model input\n        S_resized = resize(S, (128, 256), anti_aliasing=True)\n        spectrograms.append(S_resized)\n\n    # Convert to tensor and batch process\n    if spectrograms:  # Ensure there are chunks to process\n        S_tensor = torch.tensor(np.stack(spectrograms)).unsqueeze(1)  # Shape: (num_chunks, 1, 128, 256)\n        # Make predictions\n        with torch.no_grad():\n            outputs = model(S_tensor)\n        probs = outputs.cpu().numpy()  # Shape: (num_chunks, num_classes)\n\n        # Generate row_ids (e.g., soundscape_1_5, soundscape_1_10, ...)\n        soundscape_id = os.path.basename(soundscape).split('.')[0]\n        end_times = [(i + 1) * 5 for i in range(num_chunks)]\n        row_ids = [f\"{soundscape_id}_{end_time}\" for end_time in end_times]\n\n        # Create DataFrame for this soundscape\n        soundscape_preds = pd.DataFrame(probs, columns=class_labels)\n        soundscape_preds.insert(0, 'row_id', row_ids)\n        # Append to predictions\n        predictions = pd.concat([predictions, soundscape_preds], axis=0, ignore_index=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T22:04:23.158583Z","iopub.execute_input":"2025-03-11T22:04:23.158932Z","iopub.status.idle":"2025-03-11T22:04:23.166826Z","shell.execute_reply.started":"2025-03-11T22:04:23.158903Z","shell.execute_reply":"2025-03-11T22:04:23.165588Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Save to submission.csv\npredictions.to_csv('submission.csv', index=False)\nprint(\"Submission file 'submission.csv' created successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T22:06:23.318852Z","iopub.execute_input":"2025-03-11T22:06:23.319211Z","iopub.status.idle":"2025-03-11T22:06:23.325652Z","shell.execute_reply.started":"2025-03-11T22:06:23.319184Z","shell.execute_reply":"2025-03-11T22:06:23.324780Z"}},"outputs":[{"name":"stdout","text":"Submission file 'submission.csv' created successfully.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}