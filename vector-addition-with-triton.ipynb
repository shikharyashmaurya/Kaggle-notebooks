{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install triton","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T06:42:29.220904Z","iopub.execute_input":"2025-01-18T06:42:29.221247Z","iopub.status.idle":"2025-01-18T06:42:40.591423Z","shell.execute_reply.started":"2025-01-18T06:42:29.221218Z","shell.execute_reply":"2025-01-18T06:42:40.590252Z"}},"outputs":[{"name":"stdout","text":"Collecting triton\n  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton) (3.16.1)\nDownloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: triton\nSuccessfully installed triton-3.1.0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import triton\nimport triton.language as tl\nimport torch\nimport numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T06:42:40.592922Z","iopub.execute_input":"2025-01-18T06:42:40.593274Z","iopub.status.idle":"2025-01-18T06:42:43.767417Z","shell.execute_reply.started":"2025-01-18T06:42:40.593247Z","shell.execute_reply":"2025-01-18T06:42:43.766460Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"@triton.jit\ndef vector_add_kernel(\n    x_ptr,  # Pointer to first input vector\n    y_ptr,  # Pointer to second input vector\n    output_ptr,  # Pointer to output vector\n    n_elements,  # Size of vectors\n    BLOCK_SIZE: tl.constexpr,  # Number of elements each program should process\n):\n    # Get program ID\n    pid = tl.program_id(axis=0)\n    \n    # Calculate start index for this program\n    block_start = pid * BLOCK_SIZE\n    \n    # Create offset array for this block\n    offsets = block_start + tl.arange(0, BLOCK_SIZE)\n    \n    # Create mask for valid elements\n    mask = offsets < n_elements\n    \n    # Load x and y vectors\n    x = tl.load(x_ptr + offsets, mask=mask)\n    y = tl.load(y_ptr + offsets, mask=mask)\n    \n    # Perform addition\n    output = x + y\n    \n    # Store result\n    tl.store(output_ptr + offsets, output, mask=mask)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T06:42:46.785109Z","iopub.execute_input":"2025-01-18T06:42:46.785546Z","iopub.status.idle":"2025-01-18T06:42:46.792139Z","shell.execute_reply.started":"2025-01-18T06:42:46.785514Z","shell.execute_reply":"2025-01-18T06:42:46.791292Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Wrapper function to handle the kernel launch\ndef add_vectors(x: torch.Tensor, y: torch.Tensor):\n    # Assert inputs are same size and on GPU\n    assert x.shape == y.shape\n    assert x.is_cuda and y.is_cuda\n    \n    # Get vector size\n    n_elements = x.numel()\n    \n    # Create output tensor\n    output = torch.empty_like(x)\n    \n    # Calculate grid size\n    BLOCK_SIZE = 1024\n    grid = (triton.cdiv(n_elements, BLOCK_SIZE),)\n    \n    # Launch kernel\n    vector_add_kernel[grid](\n        x_ptr=x,\n        y_ptr=y,\n        output_ptr=output,\n        n_elements=n_elements,\n        BLOCK_SIZE=BLOCK_SIZE,\n    )\n    \n    return output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T06:42:50.301875Z","iopub.execute_input":"2025-01-18T06:42:50.302205Z","iopub.status.idle":"2025-01-18T06:42:50.307266Z","shell.execute_reply.started":"2025-01-18T06:42:50.302179Z","shell.execute_reply":"2025-01-18T06:42:50.306244Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Example usage\ndef main():\n    # Set problem size\n    N = 1_000_000\n    \n    # Create input vectors on CPU\n    x_cpu = torch.randn(N)\n    y_cpu = torch.randn(N)\n    \n    # Move vectors to GPU\n    x_gpu = x_cpu.cuda()\n    y_gpu = y_cpu.cuda()\n    \n    # Run Triton kernel\n    output_gpu = add_vectors(x_gpu, y_gpu)\n    \n    # Verify results\n    output_cpu = x_cpu + y_cpu\n    output_triton = output_gpu.cpu()\n    \n    print(\"Max difference:\", torch.max(torch.abs(output_cpu - output_triton)))\n    print(\"Correct:\", torch.allclose(output_cpu, output_triton))\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T06:43:09.894713Z","iopub.execute_input":"2025-01-18T06:43:09.895028Z","iopub.status.idle":"2025-01-18T06:43:09.946278Z","shell.execute_reply.started":"2025-01-18T06:43:09.894983Z","shell.execute_reply":"2025-01-18T06:43:09.944970Z"}},"outputs":[{"name":"stdout","text":"Max difference: tensor(0.)\nCorrect: True\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}